{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math as math\n",
    "from collections import OrderedDict, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(mat):\n",
    "    mat[:,2] = mat[:,0]/mat[:,1]\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet = np.zeros((100,3))\n",
    "\n",
    "#Assigning values to Triplet\n",
    "x = 1.0\n",
    "y = 1.0\n",
    "for i in range( len(triplet) ):\n",
    "    #Setting Value of X\n",
    "    triplet[i,0]=x\n",
    "    #Setting value of Y\n",
    "    triplet[i,1]=y\n",
    "    y+=1.0\n",
    "    if y==11.0:\n",
    "        x+=1.0\n",
    "        y=1.0\n",
    "\n",
    "#Calculating its function values\n",
    "triplet = f(triplet)\n",
    "np.random.shuffle(triplet)\n",
    "print (triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = triplet[ :80 , :]\n",
    "validate_data = triplet[80: , :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoFun(x):\n",
    "    return x\n",
    "\n",
    "def NoFun_Derivative(x):\n",
    "    return 1\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(x,0)\n",
    "\n",
    "def ReLU_Derivative(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def Sigmoid(x):\n",
    "    sigm = 1. / (1. + np.exp(-x))\n",
    "    return sigm\n",
    "\n",
    "def Sigmoid_Derivative(x):\n",
    "    sigm = Sigmoid(x)\n",
    "    return sigm * (1. - sigm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Number of Layers starting from 0 (Including Input, Hidden and Output )\n",
    "# So if total 6 layers write 5\n",
    "layer = 6\n",
    "\n",
    "# neuron for all Hidden layers\n",
    "n = [ 2, 3, 4, 3, 2 ]\n",
    "\n",
    "# Activation Functions in Hidden Layer\n",
    "fun = [ NoFun, ReLU, ReLU, ReLU, ReLU, ReLU, Sigmoid ]\n",
    "\n",
    "# Derivation of Activation Functions\n",
    "#         Input Layer                                 Hidden Layers                             Output Layer\n",
    "d_fun = [ NoFun_Derivative, ReLU_Derivative, ReLU_Derivative, ReLU_Derivative, ReLU_Derivative, ReLU_Derivative, Sigmoid_Derivative ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward( w, o, activation_fun, bias = 0 ):\n",
    "    z = np.matmul( w, o )\n",
    "    o = activation_fun(z+bias)\n",
    "    return z,o\n",
    "\n",
    "def ErrorFuntcion(o, y):\n",
    "    '''\n",
    "    index = np.argmax(o, axis = 1)\n",
    "    probability = o[np.arange(len(o)), index]\n",
    "    log = np.log(probability)\n",
    "    Error = -1.0 * np.sum(log) / log.shape[0]\n",
    "    return Error\n",
    "    '''\n",
    "    return ( (o-y)**2 )/2\n",
    "    \n",
    "def NN(train_X, train_Y):\n",
    "    global layer\n",
    "    global n\n",
    "    global fun\n",
    "    global d_fun\n",
    "    ita = 0.000001\n",
    "    \n",
    "    # No of Inputs\n",
    "    p = np.size(train_X, 1)\n",
    "    \n",
    "    # No of Features (of Input)\n",
    "    m = np.size(train_X, 0)\n",
    "    \n",
    "    # No of feature (of Output)\n",
    "    m_output = train_Y.shape[0]\n",
    "    \n",
    "    #Initializing w,o,z in all layers\n",
    "    w = defaultdict(np.ndarray)\n",
    "    d_w = defaultdict(np.ndarray)\n",
    "    \n",
    "    #b = defaultdict(np.ndarray)\n",
    "    #d_b = defaultdict(np.ndarray)\n",
    "    \n",
    "    o = defaultdict(np.ndarray)\n",
    "    z = defaultdict(np.ndarray)\n",
    "    \n",
    "    loss = defaultdict(np.ndarray)\n",
    "    \n",
    "    #Setting Array of W and derivative(W)\n",
    "    w[0] = np.random.rand( n[0], m )\n",
    "    d_w[0] = np.zeros(( n[0], m ))\n",
    "    for i in range(1,len(n)):\n",
    "        w[i] = np.random.rand( n[i], n[i-1] )\n",
    "        d_w[i] = np.zeros(( n[i], n[i-1] ))\n",
    "    w[layer-1] = np.random.rand( m_output, n[len(n)-1] )\n",
    "    d_w[layer-1] = np.zeros( (m_output, n[len(n)-1]))\n",
    "    \n",
    "    w_initial = w\n",
    "    \n",
    "    #Setting Array of Ones and b (bias)\n",
    "    '''\n",
    "    for i in range(1, layer):\n",
    "        #Hidden Layer starts with 1 till (layer-1)\n",
    "        b[i] = np.random.rand( n[i-1], 1 )\n",
    "        d_b[i] = np.random.rand( n[i-1], 1 )\n",
    "    b_initial = b\n",
    "    ones = np.ones( ( 1 , p ) )\n",
    "    '''\n",
    "    \n",
    "    counter = 0\n",
    "    previous_RMSE =0.1\n",
    "    RMSE = 0.2;\n",
    "    while int(RMSE * (10**7)) != int (previous_RMSE * (10**7)):\n",
    "        counter += 1\n",
    "        # Forward Calculation\n",
    "        o[0] = train_X\n",
    "        for l in range(1, layer+1):\n",
    "            # bias = np.matmul( b[l], ones )\n",
    "            z[l], o[l] = Forward(w[l-1], o[l-1], fun[l-1] )     \n",
    "        \n",
    "        #z[layer], o[layer] = Forward(w[layer-1], o[layer-1], fun[layer-1] )\n",
    "            \n",
    "        error = ErrorFuntcion(o[layer],train_Y)\n",
    "        \n",
    "        #Mean Square Error\n",
    "        MSE = np.sum(error)        \n",
    "        previous_RMSE = RMSE\n",
    "        RMSE = np.sqrt(MSE) / np.size(error)\n",
    "        \n",
    "        loss[layer] = o[layer] - train_Y\n",
    "        \n",
    "        for l in range(layer-1,-1,-1):\n",
    "            \n",
    "            # Derivative of W\n",
    "            derivative_fun = d_fun[l](z[l+1])\n",
    "            \n",
    "            loss_MUL_fun = np.multiply( loss[l+1], derivative_fun )\n",
    "            loss[l] = np.matmul ( w[l].T, loss_MUL_fun ) \n",
    "            d_w[l] = np.matmul ( loss_MUL_fun, o[l].T )\n",
    "            \n",
    "            '''\n",
    "            # Derivative of Bias\n",
    "            d_b[l] = loss_MUL_fun\n",
    "            '''\n",
    "        #Update W\n",
    "        for i in range(len(w)):\n",
    "            w[i] -= ita * d_w[i]        \n",
    "        \n",
    "        '''\n",
    "        #Update b\n",
    "        for i in range(1, layer):\n",
    "            b[i] -= ita * d_b[i]\n",
    "        '''\n",
    "    print (\"No. of Iterations:- \",counter)\n",
    "    return w, w_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Weights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Initial Weights : defaultdict(<class 'numpy.ndarray'>, {0: array([[-0.04572297, -0.53296664],\n",
    "       [ 0.55244296, -0.3252758 ]]), 1: array([[-0.11601138,  0.31499272],\n",
    "       [ 0.93281293,  0.57158996],\n",
    "       [ 0.4001148 ,  0.66330103]]), 2: array([[0.58372871, 0.88169156, 0.37570995],\n",
    "       [0.64462715, 1.03857109, 0.62290152],\n",
    "       [0.07373319, 1.01290957, 0.27937704],\n",
    "       [0.26010792, 0.98794769, 0.10613807]]), 3: array([[0.12232464, 0.59686706, 0.14218488, 0.06351082],\n",
    "       [0.34245019, 0.66960154, 0.42588861, 0.34411294],\n",
    "       [0.31291252, 0.18359324, 0.05402736, 0.63380168]]), 4: array([[0.56449502, 0.60686242, 0.5218768 ]])}) \n",
    "       \n",
    "If the above initial weights are considered the final weights brings near to correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_Y = train_data[:,2]\n",
    "train_Y = train_Y.reshape(( len(train_Y), 1))\n",
    "train_Y = train_Y.T\n",
    "\n",
    "train_X = train_data[:, 0:2]\n",
    "train_X = train_X.T\n",
    "\n",
    "w, w_initial = NN(train_X, train_Y)\n",
    "print (\"Final Weights : \", w, \"\\n\")\n",
    "print (\"Initial Weights :\", w_initial, \"\\n\")\n",
    "\n",
    "\n",
    "#print (\"Final Bias : \", b, \"\\n\")\n",
    "#print (\"Initial Bias :\", b_initial, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validating Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_Y = validate_data[:,2]\n",
    "validate_Y = validate_Y.reshape(( len(validate_Y), 1))\n",
    "validate_Y = validate_Y.T\n",
    "\n",
    "validate_X = validate_data[:, 0:2]\n",
    "validate_X = validate_X.T\n",
    "\n",
    "o = validate_X\n",
    "for l in range(1, layer+1):\n",
    "    z, o = Forward(w[l-1], o, fun[l-1] )\n",
    "\n",
    "predict_Y = o\n",
    "print (\"Predicted Result\\n\",predict_Y)\n",
    "print (\"\\nActual Result\\n\", validate_Y)\n",
    "#print (\"\\nPercentage Error\\n\",  abs(predict_Y/validate_Y)*100)\n",
    "\n",
    "error = ErrorFuntcion(predict_Y,validate_Y)\n",
    "#Mean Square Error\n",
    "MSE = np.sum(error) \n",
    "RMSE = np.sqrt(MSE) / np.size(error)\n",
    "\n",
    "print (\"\\nRoot Mean Square Error:\",RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, arr = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=True)\n",
    "\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(15)\n",
    "\n",
    "arr[0][0].scatter (validate_X[0,:], predict_Y, c='r' )\n",
    "arr[0][0].set_title('Predicted Result')\n",
    "arr[0][0].set_xlabel('X[0]')\n",
    "arr[0][0].set_ylabel('Y')\n",
    "\n",
    "arr[0][1].scatter (validate_X[0,:], validate_Y, c='b' )\n",
    "arr[0][1].set_title('Actual Result')\n",
    "arr[0][1].set_xlabel('X[0]')\n",
    "arr[0][1].set_ylabel('Y')\n",
    "\n",
    "arr[1][0].scatter (validate_X[1,:], predict_Y, c='r' )\n",
    "arr[1][0].set_title('Predicted Result')\n",
    "arr[1][0].set_xlabel('X[1]')\n",
    "arr[1][0].set_ylabel('Y')\n",
    "\n",
    "arr[1][1].scatter (validate_X[1,:], validate_Y, c='b' )\n",
    "arr[1][1].set_title('Actual Result')\n",
    "arr[1][1].set_xlabel('X[1]')\n",
    "arr[1][1].set_ylabel('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
