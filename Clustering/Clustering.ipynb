{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math as math\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"faithful.txt\", sep= \"     \", header=None)\n",
    "\n",
    "data.columns = [\"Index\", \"Eruptions\", \"Waiting\"]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Eruptions'],data['Waiting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data[:250]\n",
    "testing_data = data[250:]\n",
    "\n",
    "train_X = training_data[[\"Eruptions\"]].values\n",
    "train_Y = training_data[[\"Waiting\"]].values\n",
    "\n",
    "test_X = testing_data[[\"Eruptions\"]].values\n",
    "test_Y = testing_data[[\"Waiting\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(training_data['Eruptions'],training_data['Waiting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(testing_data['Eruptions'],testing_data['Waiting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_Train(x,clusterSize = 2):\n",
    "    #By above data visualization we know we need 2 clusters\n",
    "    #Hence k=2\n",
    "    k = clusterSize\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "\n",
    "    phi = np.random.rand(k,p)\n",
    "    total = np.sum(phi)\n",
    "    phi = phi/total #sum of all phi value = 1\n",
    "    mu = np.random.rand(k,p)\n",
    "    sigma = np.random.rand(k,p)    \n",
    "    w = np.ndarray(shape=(n,k,p))\n",
    "    preW = np.ndarray(shape=(p))\n",
    "    apple = 0\n",
    "    isConverged = False\n",
    "    \n",
    "    while not isConverged:\n",
    "        if apple >= 1000:\n",
    "            break\n",
    "        apple+=1\n",
    "\n",
    "        #Calculation of Wij\n",
    "        sum_of_all_probability = np.zeros((n,1,p))\n",
    "        probability = np.zeros((n,k,p))\n",
    "        for i in range(n):\n",
    "            for j in range(k):\n",
    "                dij = x[i] - mu[j] \n",
    "                dijSquare = - ( dij.T * dij )\n",
    "                sigSquare = 2 * sigma[j]**2\n",
    "                tempExp = np.exp( dijSquare / sigSquare )\n",
    "                constant = 1 / ( (2*math.pi)**(p/2) * sigma[j] )\n",
    "                probability[i,j] = ( constant * tempExp * phi[j] )\n",
    "                sum_of_all_probability[i] += probability[i,j]\n",
    "\n",
    "        preW = np.copy(w)\n",
    "        for i in range(n):\n",
    "                for j in range(k):\n",
    "                    w[i,j] = probability[i,j] / sum_of_all_probability[i]\n",
    "        \n",
    "        if (preW == w).all():\n",
    "            isConverged = True\n",
    "        \n",
    "        #Calculation of mu sigma and phi\n",
    "        for j in range(k):\n",
    "            sum_W_X_MU = 1\n",
    "            sum_W_X = 1\n",
    "            sum_W = 2\n",
    "\n",
    "            #Calculation of mu\n",
    "            for i in range(n):\n",
    "                sum_W_X +=  w[i,j] * x[i]\n",
    "                sum_W += w[i,j]  \n",
    "            mu[j] = sum_W_X / sum_W\n",
    "            \n",
    "            #Calculation of sigma\n",
    "            for i in range(n):\n",
    "                sum_W_X_MU += w[i,j] * (x[i]-mu[j])**2                \n",
    "            sigma[j] = ( sum_W_X_MU / sum_W )**0.5\n",
    "                \n",
    "            #Calculation of phi\n",
    "            phi[j] = sum_W / n\n",
    "            \n",
    "    print (\"Number of Iterations: \",apple)    \n",
    "    return w, mu, sigma, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Probability(x, mu, sigma, phi, clusterSize=2):\n",
    "    k = clusterSize\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    w = np.ndarray(shape=(n,k,p))\n",
    "    sum_of_all_probability = np.zeros((n,1,p))\n",
    "    probability = np.zeros((n,k,p))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            dij = x[i] - mu[j] \n",
    "            dijSquare = - ( dij.T * dij )\n",
    "            sigSquare = 2 * sigma[j]**2\n",
    "            tempExp = np.exp( dijSquare / sigSquare )\n",
    "            constant = 1 / ( (2*math.pi)**(p/2) * sigma[j] )\n",
    "            probability[i,j] = ( constant * tempExp * phi[j] )\n",
    "            sum_of_all_probability[i] += probability[i,j]\n",
    "    \n",
    "    preW = np.copy(w)       \n",
    "    for i in range(n):\n",
    "            for j in range(k):\n",
    "                w[i,j] = probability[i,j] / sum_of_all_probability[i]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cal_J (w, mu, sigma, phi, x, clusterSize = 2):\n",
    "    k = clusterSize\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    \n",
    "    funJ = np.zeros((n,k))\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            const = math.log( 1/ (2* math.pi)**(p/2) )\n",
    "            lnSig = np.log( sigma[j] )\n",
    "            \n",
    "            dijSquare = (x[i] - mu[j])**2\n",
    "            sigSquare = 2 * sigma[j]**2\n",
    "            exp = dijSquare/sigSquare\n",
    "            \n",
    "            lnPhi = np.log( phi[j] )\n",
    "            lnW = np.log ( w[i,j] )\n",
    "            \n",
    "            funJ += w[i,j] * ( const - lnSig - exp + lnPhi - lnW )\n",
    "    \n",
    "    return funJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDict(w):\n",
    "    dic = defaultdict(list)\n",
    "    i = 0\n",
    "    for c in w:\n",
    "        if c[0] > 0.5:\n",
    "            dic[0].append(i)\n",
    "        if c[1] > 0.5:\n",
    "            dic[1].append(i)\n",
    "        i += 1 \n",
    "    return dic\n",
    "\n",
    "def PlotGraph(data, dic):\n",
    "    for rowind in range(0, len(data)):\n",
    "        temp = data.iloc[[rowind]]\n",
    "        if rowind in dic[0]:\n",
    "            plt.plot(temp[\"Eruptions\"],temp[\"Waiting\"], 'b+')\n",
    "        else:\n",
    "            plt.plot(temp[\"Eruptions\"],temp[\"Waiting\"], 'r+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying the Data into clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, mu, sigma, phi = EM_Train(train_X)\n",
    "J = Cal_J(w, mu, sigma, phi, train_X)\n",
    "trainingCluster = CreateDict(w)\n",
    "PlotGraph(training_data, trainingCluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now Dividing Data into Clusters\n",
    "train_clutster_1 = training_data.loc[ training_data[\"Index\"].isin( trainingCluster[0] ) ]\n",
    "train_clutster_2 = training_data.loc[ training_data[\"Index\"].isin( trainingCluster[1] ) ]\n",
    "\n",
    "train_X_clutster_1 = train_clutster_1[[\"Eruptions\"]].values\n",
    "train_Y_clutster_1 = train_clutster_1[[\"Waiting\"]].values\n",
    "\n",
    "train_X_clutster_2 = train_clutster_2[[\"Eruptions\"]].values\n",
    "train_Y_clutster_2 = train_clutster_2[[\"Waiting\"]].values\n",
    "\n",
    "#For Each cluster Finding the theta value\n",
    "#Basically applying linear regression for each cluster\n",
    "def Linear_Train(training_data_X, training_data_Y):\n",
    "    xT = np.transpose(training_data_X)\n",
    "    xTx = np.matmul ( xT, training_data_X )\n",
    "    inverse_xTx = np.linalg.inv ( xTx )\n",
    "    xTy = np.matmul ( xT, training_data_Y )\n",
    "    theta_function =  np.matmul (inverse_xTx, xTy)\n",
    "    return theta_function\n",
    "\n",
    "def Cal_Error(validating_data_X, validating_data_Y, theta_function):\n",
    "    #Now Validation of Data\n",
    "    error_function = ( np.matmul( validating_data_X, theta_function ) - validating_data_Y ) ** 2\n",
    "    mean_square_error = np.sum(error_function)\n",
    "    root_mean_square_error = np.sqrt(mean_square_error) / np.size(error_function)\n",
    "    return root_mean_square_error\n",
    "\n",
    "theta_cluster_1 = Linear_Train(train_X_clutster_1,train_Y_clutster_1)\n",
    "theta_cluster_2 = Linear_Train(train_X_clutster_2,train_Y_clutster_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_1 = Cal_Error(train_X_clutster_1,train_Y_clutster_1,theta_cluster_1)\n",
    "rmse_2 = Cal_Error(train_X_clutster_2,train_Y_clutster_2,theta_cluster_2)\n",
    "\n",
    "print (\"Root Mean Square Error of Cluster 1 :\",rmse_1)\n",
    "print (\"Root Mean Square Error of Cluster 2 :\",rmse_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_w = Find_Probability(test_X, mu, sigma, phi)\n",
    "predictCluster  = CreateDict(predict_w)\n",
    "\n",
    "predict_Y = np.ndarray((test_Y.shape[0], test_Y.shape[1]))\n",
    "\n",
    "for rowind in range(len(test_X)):\n",
    "    temp = test_X[rowind,:]\n",
    "    if rowind in predictCluster[0]:\n",
    "        predict_Y[rowind] = np.matmul(temp, theta_cluster_1)\n",
    "    else:\n",
    "        predict_Y[rowind] = np.matmul(temp, theta_cluster_2)\n",
    "        \n",
    "PlotGraph(testing_data, predictCluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, arr = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True)\n",
    "\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(7)\n",
    "\n",
    "arr[0].scatter (test_X[:,0], predict_Y, c='r' )\n",
    "arr[0].set_title('Predicted Result')\n",
    "arr[0].set_xlabel('Eruption')\n",
    "arr[0].set_ylabel('Waiting')\n",
    "\n",
    "arr[1].scatter (test_X[:,0], test_Y, c='b' )\n",
    "arr[1].set_title('Actual Result')\n",
    "arr[1].set_xlabel('Eruption')\n",
    "arr[1].set_ylabel('Waiting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, arr = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True)\n",
    "\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(4)\n",
    "\n",
    "arr[0].hist(predict_Y)\n",
    "arr[0].set_title('Predicted Result')\n",
    "\n",
    "arr[1].hist(test_Y)\n",
    "arr[1].set_title('Actual Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
