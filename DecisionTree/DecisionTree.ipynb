{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all columns and rows from the file\n",
    "ds1_train = pd.read_csv('dataset_1/training_set.csv')\n",
    "ds1_val = pd.read_csv('dataset_1/validation_set.csv')\n",
    "ds1_test = pd.read_csv('dataset_1/test_set.csv')\n",
    "\n",
    "ds2_train = pd.read_csv('dataset_2/training_set.csv')\n",
    "ds2_val = pd.read_csv('dataset_2/validation_set.csv')\n",
    "ds2_test = pd.read_csv('dataset_2/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataSet 1\n",
    "ds1_train_X = ds1_train.iloc[ 0: , 0: len( ds1_train.columns ) - 1  ].values\n",
    "ds1_train_Y = ds1_train.iloc[ 0: , len( ds1_train.columns ) - 1: len( ds1_train.columns ) ].values\n",
    "\n",
    "ds1_val_X = ds1_val.iloc[ 0: , 0: len( ds1_val.columns ) - 1  ].values\n",
    "ds1_val_Y = ds1_val.iloc[ 0: , len( ds1_val.columns ) - 1: len( ds1_val.columns ) ].values\n",
    "\n",
    "ds1_test_X = ds1_test.iloc[ 0: , 0: len( ds1_test.columns ) - 1  ].values\n",
    "ds1_test_Y = ds1_test.iloc[ 0: , len( ds1_test.columns ) - 1: len( ds1_test.columns ) ].values\n",
    "\n",
    "#DataSet 2\n",
    "ds2_train_X = ds2_train.iloc[ 0: , 0: len( ds2_train.columns ) - 1  ].values\n",
    "ds2_train_Y = ds2_train.iloc[ 0: , len( ds2_train.columns ) - 1: len( ds2_train.columns ) ].values\n",
    "\n",
    "ds2_val_X = ds2_val.iloc[ 0: , 0: len( ds2_val.columns ) - 1  ].values\n",
    "ds2_val_Y = ds2_val.iloc[ 0: , len( ds2_val.columns ) - 1: len( ds2_val.columns ) ].values\n",
    "\n",
    "ds2_test_X = ds2_test.iloc[ 0: , 0: len( ds2_test.columns ) - 1  ].values\n",
    "ds2_test_Y = ds2_test.iloc[ 0: , len( ds2_test.columns ) - 1: len( ds2_test.columns ) ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Some \"Helper\" functions ---------------\n",
    "# Segregating out instances that take a particular value\n",
    "# attributearray is an N x 1 array.\n",
    "def segregate(attributearray, value):\n",
    "    outlist = []\n",
    "    for i in range ( len(attributearray) ):\n",
    "        if attributearray[i] == value:\n",
    "            outlist.append(i)  #  Append \"i\" to outlist\n",
    "    return outlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming labels take values 1..M.\n",
    "def computeEntropy(labels):\n",
    "    entropy = 0\n",
    "    UniqueValuesInLabels =  np.unique( labels )\n",
    "    for i in UniqueValuesInLabels:\n",
    "        probability_i = len(segregate(labels, i)) / len(labels)\n",
    "        entropy -= probability_i * math.log2(probability_i)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most frequent value. Assuming labels take values 1..M \n",
    "def mostFrequentlyOccurringValue(labels):\n",
    "    bestCount = -math.inf\n",
    "    bestId = None\n",
    "    UniqueValuesInLabels =  np.unique( labels )\n",
    "    for i in UniqueValuesInLabels:\n",
    "        count_i = len(segregate(labels,i))\n",
    "        if count_i > bestCount:\n",
    "            bestCount = count_i\n",
    "            bestId = i\n",
    "    return bestId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeVarianceImpurity(labels):\n",
    "    vi = 1\n",
    "    UniqueValuesInLabels =  np.unique( labels )\n",
    "    for i in UniqueValuesInLabels:\n",
    "        probability_i = len(segregate(labels, i)) / len(labels)\n",
    "        vi *= probability_i\n",
    "    return vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InformationGainByVI( S, X ):\n",
    "    vi = computeVarianceImpurity( S )\n",
    "    UniqueValuesofX = np.unique(X)\n",
    "    for Y in UniqueValuesofX:\n",
    "        ids = segregate( X, Y )\n",
    "        pr_x = len(ids) / len(S)\n",
    "        vi_Sx = computeVarianceImpurity( S[ids] )\n",
    "        vi -= pr_x * vi_Sx\n",
    "    return vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, attributes, labels, methodToUse ):\n",
    "        self.parent = None\n",
    "        self.nodeGainRation = float(0.0)\n",
    "        self.nodeInformationGain = float(0.0)\n",
    "        self.isLeaf = False\n",
    "        self.majorityClass = int(0)\n",
    "        self.bestAttribute = int(0)\n",
    "        self.children = {}\n",
    "        \n",
    "        if methodToUse == \"GainRatio\":\n",
    "            self.BuildTreeByGainRatio( attributes, labels )\n",
    "        if methodToUse == \"VarianceImpurity\":\n",
    "            self.BuildTreeByVI( attributes, labels )\n",
    "            \n",
    "    def BuildTreeByVI( self, attributes, labels ): \n",
    "        numInstances = len( labels )\n",
    "        nodeInformation = numInstances * computeVarianceImpurity(labels)\n",
    "        self.majorityClass = mostFrequentlyOccurringValue( labels )\n",
    "        \n",
    "        if nodeInformation == 0:\n",
    "            self.isLeaf = True\n",
    "            return\n",
    "        \n",
    "        bestAttribute = None\n",
    "        bestInformationGain = -math.inf\n",
    "        loop = 0\n",
    "        for X in attributes.T:\n",
    "            infoGain = InformationGainByVI(labels,X)                  \n",
    "            \n",
    "            if infoGain > bestInformationGain:\n",
    "                bestInformationGain = infoGain\n",
    "                bestAttribute = loop\n",
    "            loop += 1\n",
    "\n",
    "        if bestInformationGain == -math.inf or bestInformationGain == 0:\n",
    "            self.isLeaf = True\n",
    "            return \n",
    "        \n",
    "        # Otherwise split by the best attribute\n",
    "        self.bestAttribute = bestAttribute\n",
    "        self.nodeInformationGain = bestInformationGain\n",
    "        UniqueValuesInX =  np.unique( attributes[:,bestAttribute] )\n",
    "        for Y in UniqueValuesInX:\n",
    "            ids = segregate(attributes[:,bestAttribute], Y)\n",
    "            self.children[Y] =  DecisionTree(attributes[ids], labels[ids], \"VarianceImpurity\")\n",
    "            self.children[Y].parent = self\n",
    "        return\n",
    "        \n",
    "                                            \n",
    "    def BuildTreeByGainRatio( self, attributes, labels ):\n",
    "        numInstances = len( labels )\n",
    "        nodeInformation = numInstances * computeEntropy(labels)\n",
    "        self.majorityClass = mostFrequentlyOccurringValue( labels )\n",
    "        \n",
    "        if nodeInformation == 0:\n",
    "            self.isLeaf = True\n",
    "            return\n",
    "        \n",
    "        bestAttribute = None\n",
    "        bestInformationGain = -math.inf\n",
    "        bestGainRatio = -math.inf\n",
    "        loop = 0\n",
    "        for X in attributes.T:\n",
    "            conditionalInfo = 0\n",
    "            attributeEntropy = 0\n",
    "            attributeCount = {}\n",
    "            UniqueValuesInX =  np.unique( X )\n",
    "            for Y in UniqueValuesInX:\n",
    "                ids = segregate( X, Y )\n",
    "                attributeCount[Y] = len(ids)\n",
    "                conditionalInfo += len(ids) * computeEntropy(labels[ids])\n",
    "\n",
    "                attributeInformationGain =  nodeInformation - conditionalInfo\n",
    "            attributeCount = np.array(list(attributeCount.items()), dtype=type(attributeCount))\n",
    "            \n",
    "            if computeEntropy(attributeCount[:,1]) != 0:\n",
    "                gainRatio = attributeInformationGain / computeEntropy(attributeCount[:,1])\n",
    "                if gainRatio > bestGainRatio:\n",
    "                    bestInformationGain = attributeInformationGain\n",
    "                    bestGainRatio = gainRatio\n",
    "                    bestAttribute = loop\n",
    "            loop+=1\n",
    "        \n",
    "        #If no attribute provides andy gain, this node cannot be split further\n",
    "        if bestGainRatio == 0 or bestGainRatio == -math.inf:\n",
    "            self.isLeaf = True\n",
    "            return\n",
    "        \n",
    "        # Otherwise split by the best attribute\n",
    "        self.bestAttribute = bestAttribute\n",
    "        self.nodeGainRatio = bestGainRatio\n",
    "        self.nodeInformationGain = bestInformationGain\n",
    "        UniqueValuesInX =  np.unique( attributes[:,bestAttribute] )\n",
    "        for Y in UniqueValuesInX:\n",
    "            ids = segregate(attributes[:,bestAttribute], Y)\n",
    "            self.children[Y] =  DecisionTree(attributes[ids], labels[ids], \"GainRatio\")\n",
    "            self.children[Y].parent = self\n",
    "        return\n",
    "\n",
    "    def RemoveChild(self, twig):\n",
    "        if self == twig:\n",
    "            self.chidren = None  # Kill the chilren\n",
    "            self.isLeaf = True\n",
    "            self.nodeInformationGain = 0\n",
    "            return  \n",
    "        else:\n",
    "            for val,child in self.children.items():\n",
    "                child.RemoveChild( twig )\n",
    "\n",
    "    #print (nodeInformation)\n",
    "    def Evaluate(self, testAttributes):\n",
    "        #print(testAttributes)\n",
    "        if (self.isLeaf):\n",
    "            return self.majorityClass\n",
    "        else:\n",
    "            return self.children[\n",
    "                testAttributes[self.bestAttribute]\n",
    "            ].Evaluate(testAttributes)\n",
    "        \n",
    "    def PrintRec(self, columnName, ans, bestAttribute):\n",
    "        if (self.isLeaf):\n",
    "            ans.append( str( self.majorityClass ) ) \n",
    "            return ans\n",
    "        else:\n",
    "            \n",
    "            ans.append ( str( columnName[bestAttribute] ) + \" = 0 : \" )\n",
    "            self.children[0].PrintRec( columnName, ans, self.children[0].bestAttribute )\n",
    "            \n",
    "            ans.append ( str( columnName[bestAttribute] ) + \" = 1 : \" )\n",
    "            self.children[1].PrintRec( columnName, ans, self.children[1].bestAttribute )\n",
    "            \n",
    "            return ans\n",
    "            \n",
    "    def PrintTree(self, columnNames ):\n",
    "        ans = []\n",
    "        ans = self.PrintRec( columnNames, ans, self.bestAttribute)\n",
    "        answer = \"\"\n",
    "        loop = 0\n",
    "        dic_loop = {}\n",
    "        \n",
    "        for i in ans:\n",
    "            temp = True\n",
    "            if i == \"0\":\n",
    "                answer+=i\n",
    "                temp = False\n",
    "            if i == \"1\":\n",
    "                answer+=i\n",
    "                temp = False\n",
    "            \n",
    "            if temp:\n",
    "                if dic_loop.get(i[0:2]) == None:\n",
    "                    dic_loop[ i[0:2] ] = loop\n",
    "                else:\n",
    "                    loop = dic_loop.get(i[0:2])\n",
    "\n",
    "                answer += \"\\n\"\n",
    "                for j in range(loop):\n",
    "                    answer+= \"| \"\n",
    "                answer += i\n",
    "            loop +=1\n",
    "        print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracy( dt, X, Y):\n",
    "    predict_Y = np.zeros( ( Y.shape ) )\n",
    "    for i in range( len(X) ):\n",
    "        predict_Y[i] = dt.Evaluate( X[i,:] )\n",
    "\n",
    "    no_of_matches = np.sum( predict_Y == Y)\n",
    "    accuracy = no_of_matches/len(Y)\n",
    "    \n",
    "    #Accuracy Calculation\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purning Algorithm by Classification Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count leaves in a tree\n",
    "def CountLeaves(dt):\n",
    "    if dt.isLeaf:\n",
    "        return 1\n",
    "    else:\n",
    "        n = 0\n",
    "        for val,child in dt.children.items():\n",
    "            n += CountLeaves(child)\n",
    "    return n\n",
    "\n",
    "# Check if a node is a twig\n",
    "def isTwig(dt):\n",
    "    for val,child in dt.children.items():\n",
    "        if not child.isLeaf:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# First create an empty list of error counts at nodes\n",
    "def CreateNodeList( dt, nodeError={} ):\n",
    "    nodeError[dt] = 0\n",
    "    for val,child in dt.children.items():\n",
    "        CreateNodeList(child,nodeError)\n",
    "    return nodeError\n",
    "\n",
    "# Pass a single instance down the tree and note node errors\n",
    "def ClassifyValidationDataInstance( dt, validationDataInstance, nodeError ):\n",
    "    labels = validationDataInstance[len(validationDataInstance)-1]\n",
    "    if dt.majorityClass != labels:\n",
    "        nodeError[dt] += 1\n",
    "    if not dt.isLeaf:\n",
    "        childNode = dt.children[ validationDataInstance[dt.bestAttribute] ]\n",
    "        ClassifyValidationDataInstance( childNode, validationDataInstance, nodeError )\n",
    "    return\n",
    "\n",
    "# Count total node errors for validation data\n",
    "def ClassifyValidationData(dt, validationData):\n",
    "    nodeErrorCounts = CreateNodeList(dt)\n",
    "    for instance in validationData:\n",
    "        ClassifyValidationDataInstance(dt, instance, nodeErrorCounts)\n",
    "    return nodeErrorCounts\n",
    "\n",
    "# Second pass:  Create a heap with twigs using nodeErrorCounts\n",
    "def CollectTwigsByErrorCount(dt, nodeErrorCounts, heap=[]):\n",
    "    if isTwig(dt):\n",
    "        # Count how much the error would increase if the twig were trimmed\n",
    "        twigErrorIncrease = nodeErrorCounts[dt]\n",
    "        for val,child in dt.children.items():\n",
    "            twigErrorIncrease -= nodeErrorCounts[child]\n",
    "        heap.append([twigErrorIncrease, dt])\n",
    "    else:\n",
    "        for val,child in dt.children.items():\n",
    "            CollectTwigsByErrorCount(child, nodeErrorCounts, heap)\n",
    "    return heap\n",
    "\n",
    "# Third pass: Prune a tree to have nLeaves leaves\n",
    "# Assuming heappop pops smallest value\n",
    "def PruneByClassificationError(dt, validationData, nLeaves = -1):\n",
    "    # First obtain error counts for validation data\n",
    "    nodeErrorCounts = ClassifyValidationData(dt, validationData)\n",
    "    \n",
    "    # Get Twig Heap\n",
    "    twigHeap = CollectTwigsByErrorCount(dt, nodeErrorCounts)\n",
    "\n",
    "    totalLeaves = CountLeaves(dt)\n",
    "    while totalLeaves > nLeaves:\n",
    "\n",
    "        #Find index of minimum value of Twig from the Heap\n",
    "        minVal = math.inf\n",
    "        twigHeap_index = -1\n",
    "        loop = 0\n",
    "        for x in twigHeap:\n",
    "            if x[0] < minVal:\n",
    "                twigHeap_index = loop\n",
    "            loop+=1\n",
    "        \n",
    "        if twigHeap[twigHeap_index][0] > 0 and nLeaves == -1:\n",
    "            break\n",
    "        \n",
    "        twig = twigHeap[twigHeap_index][1]\n",
    "        twigHeap.pop(twigHeap_index)\n",
    "        totalLeaves -= (len(twig.children) - 1) \n",
    "        parent = twig.parent\n",
    "        \n",
    "        #Removing Twig from the original tree\n",
    "        dt.RemoveChild( twig )\n",
    "\n",
    "        # Check if the parent is a twig and, if so, put it in the heap\n",
    "        if isTwig(parent):\n",
    "            twigErrorIncrease = nodeErrorCounts[parent]\n",
    "            for val,child in parent.children.items():\n",
    "                twigErrorIncrease -= nodeErrorCounts[child]\n",
    "            twigHeap.append([twigErrorIncrease, parent])\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pruning:--- \n",
      "\n",
      "XI = 0 : \n",
      "| XG = 0 : 0\n",
      "| XG = 1 : \n",
      "| | XS = 0 : \n",
      "| | | XJ = 0 : 0\n",
      "| | | XJ = 1 : \n",
      "| | | | XQ = 0 : \n",
      "| | | | | XE = 0 : 0\n",
      "| | | | | XE = 1 : 1\n",
      "| | | | XQ = 1 : 0\n",
      "| | XS = 1 : 0\n",
      "XI = 1 : \n",
      "| XH = 0 : \n",
      "| | | | | XE = 0 : 0\n",
      "| | | | | XE = 1 : \n",
      "| | | | | | XL = 0 : \n",
      "| | | XJ = 0 : 0\n",
      "| | | XJ = 1 : 0\n",
      "| | | | | | XL = 1 : 0\n",
      "| XH = 1 : \n",
      "| | XC = 0 : \n",
      "| | | XN = 0 : \n",
      "| | | | XD = 0 : \n",
      "| | | | | XF = 0 : 0\n",
      "| | | | | XF = 1 : \n",
      "| | | | | | XU = 0 : \n",
      "| | | | | | | XB = 0 : 1\n",
      "| | | | | | | XB = 1 : 1\n",
      "| | | | | | XU = 1 : 1\n",
      "| | | | XD = 1 : \n",
      "| | | | | XP = 0 : 0\n",
      "| | | | | XP = 1 : \n",
      "| | XS = 0 : 0\n",
      "| | XS = 1 : 1\n",
      "| | | XN = 1 : \n",
      "| | | | | | | XB = 0 : \n",
      "| | | | | | | | XR = 0 : \n",
      "| | | | | XE = 0 : \n",
      "| XG = 0 : 1\n",
      "| XG = 1 : 0\n",
      "| | | | | XE = 1 : \n",
      "| | | XJ = 0 : 1\n",
      "| | | XJ = 1 : \n",
      "| | | | | XP = 0 : 1\n",
      "| | | | | XP = 1 : 1\n",
      "| | | | | | | | XR = 1 : \n",
      "| | | | | | XU = 0 : 0\n",
      "| | | | | | XU = 1 : 0\n",
      "| | | | | | | XB = 1 : \n",
      "| | | | | XF = 0 : \n",
      "| XG = 0 : 1\n",
      "| XG = 1 : 1\n",
      "| | | | | XF = 1 : \n",
      "| | | | | XE = 0 : 1\n",
      "| | | | | XE = 1 : 1\n",
      "| | XC = 1 : \n",
      "| | XS = 0 : \n",
      "| | | | | XE = 0 : 0\n",
      "| | | | | XE = 1 : \n",
      "| | | | | XP = 0 : 0\n",
      "| | | | | XP = 1 : 0\n",
      "| | XS = 1 : \n",
      "| | | | | XP = 0 : \n",
      "| | | | | XF = 0 : 0\n",
      "| | | | | XF = 1 : 0\n",
      "| | | | | XP = 1 : \n",
      "| | | | XQ = 0 : 1\n",
      "| | | | XQ = 1 : 1\n",
      "Accuracy on Validation Data :- 0.8716666666666667\n",
      "Accuracy on Testing Data :-- 0.845\n",
      "\n",
      "After Pruning:--- \n",
      "\n",
      "XI = 0 : \n",
      "| XG = 0 : 0\n",
      "| XG = 1 : \n",
      "| | XS = 0 : \n",
      "| | | XJ = 0 : 0\n",
      "| | | XJ = 1 : \n",
      "| | | | XQ = 0 : \n",
      "| | | | | XE = 0 : 0\n",
      "| | | | | XE = 1 : 1\n",
      "| | | | XQ = 1 : 0\n",
      "| | XS = 1 : 0\n",
      "XI = 1 : \n",
      "| XH = 0 : \n",
      "| | | | | XE = 0 : 0\n",
      "| | | | | XE = 1 : \n",
      "| | | | | | XL = 0 : \n",
      "| | | XJ = 0 : 0\n",
      "| | | XJ = 1 : 0\n",
      "| | | | | | XL = 1 : 0\n",
      "| XH = 1 : \n",
      "| | XC = 0 : \n",
      "| | | XN = 0 : \n",
      "| | | | XD = 0 : \n",
      "| | | | | XF = 0 : 0\n",
      "| | | | | XF = 1 : \n",
      "| | | | | | XU = 0 : \n",
      "| | | | | | | XB = 0 : 1\n",
      "| | | | | | | XB = 1 : 1\n",
      "| | | | | | XU = 1 : 1\n",
      "| | | | XD = 1 : \n",
      "| | | | | XP = 0 : 0\n",
      "| | | | | XP = 1 : \n",
      "| | XS = 0 : 0\n",
      "| | XS = 1 : 1\n",
      "| | | XN = 1 : \n",
      "| | | | | | | XB = 0 : \n",
      "| | | | | | | | XR = 0 : \n",
      "| | | | | XE = 0 : \n",
      "| XG = 0 : 1\n",
      "| XG = 1 : 0\n",
      "| | | | | XE = 1 : \n",
      "| | | XJ = 0 : 1\n",
      "| | | XJ = 1 : \n",
      "| | | | | XP = 0 : 1\n",
      "| | | | | XP = 1 : 1\n",
      "| | | | | | | | XR = 1 : \n",
      "| | | | | | XU = 0 : 0\n",
      "| | | | | | XU = 1 : 0\n",
      "| | | | | | | XB = 1 : \n",
      "| | | | | XF = 0 : \n",
      "| XG = 0 : 1\n",
      "| XG = 1 : 1\n",
      "| | | | | XF = 1 : \n",
      "| | | | | XE = 0 : 1\n",
      "| | | | | XE = 1 : 1\n",
      "| | XC = 1 : \n",
      "| | XS = 0 : \n",
      "| | | | | XE = 0 : 0\n",
      "| | | | | XE = 1 : \n",
      "| | | | | XP = 0 : 0\n",
      "| | | | | XP = 1 : 0\n",
      "| | XS = 1 : \n",
      "| | | | | XP = 0 : 0\n",
      "| | | | | XP = 1 : 1\n",
      "Accuracy on Validation Data :- 0.8716666666666667\n",
      "Accuracy on Testing Data :-- 0.845\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree( ds1_train_X, ds1_train_Y, \"VarianceImpurity\"  )\n",
    "\n",
    "print( \"Before Pruning:--- \")\n",
    "dt.PrintTree( ds1_train.columns )\n",
    "print( \"Accuracy on Validation Data :- \" + str(CalculateAccuracy( dt, ds1_val_X, ds1_val_Y ) ) )\n",
    "print( \"Accuracy on Testing Data :-- \" + str(CalculateAccuracy( dt, ds1_test_X, ds1_test_Y ) ) )\n",
    "\n",
    "dt = PruneByClassificationError( dt, np.concatenate((ds1_val_X,ds1_val_Y),axis=1) )\n",
    "\n",
    "print( \"\\nAfter Pruning:--- \")\n",
    "dt.PrintTree( ds1_train.columns )\n",
    "print( \"Accuracy on Validation Data :- \" + str(CalculateAccuracy( dt, ds1_val_X, ds1_val_Y ) ) )\n",
    "print( \"Accuracy on Testing Data :-- \" + str(CalculateAccuracy( dt, ds1_test_X, ds1_test_Y ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pruning:--- \n",
      "Accuracy on Validation Data :- 0.6616666666666666\n",
      "Accuracy on Testing Data :-- 0.6383333333333333\n",
      "\n",
      "After Pruning:--- \n",
      "Accuracy on Validation Data :- 0.67\n",
      "Accuracy on Testing Data :-- 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree( ds2_train_X, ds2_train_Y, \"VarianceImpurity\"  )\n",
    "\n",
    "print( \"Before Pruning:--- \")\n",
    "#dt.PrintTree( ds2_train.columns )\n",
    "print( \"Accuracy on Validation Data :- \" + str(CalculateAccuracy( dt, ds2_val_X, ds2_val_Y ) ) )\n",
    "print( \"Accuracy on Testing Data :-- \" + str(CalculateAccuracy( dt, ds2_test_X, ds2_test_Y ) ) )\n",
    "\n",
    "dt = PruneByClassificationError( dt, np.concatenate((ds2_val_X,ds2_val_Y),axis=1) )\n",
    "\n",
    "print( \"\\nAfter Pruning:--- \")\n",
    "#dt.PrintTree( ds2_train.columns )\n",
    "print( \"Accuracy on Validation Data :- \" + str(CalculateAccuracy( dt, ds2_val_X, ds2_val_Y ) ) )\n",
    "print( \"Accuracy on Testing Data :-- \" + str(CalculateAccuracy( dt, ds2_test_X, ds2_test_Y ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pruning:--- \n",
      "Accuracy on Validation Data :- 0.965\n",
      "Accuracy on Testing Data :-- 0.9566666666666667\n",
      "\n",
      "After Pruning:--- \n",
      "Accuracy on Validation Data :- 0.965\n",
      "Accuracy on Testing Data :-- 0.9566666666666667\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree( ds1_train_X, ds1_train_Y, \"GainRatio\"  )\n",
    "print( \"Before Pruning:--- \")\n",
    "#dt.PrintTree( ds1_train.columns )\n",
    "print( \"Accuracy on Validation Data :- \" + str(CalculateAccuracy( dt, ds1_val_X, ds1_val_Y ) ) )\n",
    "print( \"Accuracy on Testing Data :-- \" + str(CalculateAccuracy( dt, ds1_test_X, ds1_test_Y ) ) )\n",
    "\n",
    "dt = PruneByClassificationError( dt, np.concatenate((ds1_val_X,ds1_val_Y),axis=1) )\n",
    "\n",
    "print( \"\\nAfter Pruning:--- \")\n",
    "#dt.PrintTree( ds1_train.columns )\n",
    "print( \"Accuracy on Validation Data :- \" + str(CalculateAccuracy( dt, ds1_val_X, ds1_val_Y ) ) )\n",
    "print( \"Accuracy on Testing Data :-- \" + str(CalculateAccuracy( dt, ds1_test_X, ds1_test_Y ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pruning:--- \n",
      "Accuracy on Validation Data :- 0.75\n",
      "Accuracy on Testing Data :-- 0.7266666666666667\n",
      "\n",
      "After Pruning:--- \n",
      "Accuracy on Validation Data :- 0.7583333333333333\n",
      "Accuracy on Testing Data :-- 0.7316666666666667\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree( ds2_train_X, ds2_train_Y, \"GainRatio\"  )\n",
    "\n",
    "print( \"Before Pruning:--- \")\n",
    "#dt.PrintTree( ds2_train.columns )\n",
    "print( \"Accuracy on Validation Data :- \" + str(CalculateAccuracy( dt, ds2_val_X, ds2_val_Y ) ) )\n",
    "print( \"Accuracy on Testing Data :-- \" + str(CalculateAccuracy( dt, ds2_test_X, ds2_test_Y ) ) )\n",
    "\n",
    "dt = PruneByClassificationError( dt, np.concatenate((ds2_val_X,ds2_val_Y),axis=1) )\n",
    "\n",
    "print( \"\\nAfter Pruning:--- \")\n",
    "#dt.PrintTree( ds2_train.columns )\n",
    "print( \"Accuracy on Validation Data :- \" + str(CalculateAccuracy( dt, ds2_val_X, ds2_val_Y ) ) )\n",
    "print( \"Accuracy on Testing Data :-- \" + str(CalculateAccuracy( dt, ds2_test_X, ds2_test_Y ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
